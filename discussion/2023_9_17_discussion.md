# 2023.09.17讨论

## 目前计划实现的内容

本次讨论主要围绕两方面展开：

首先是对于FaceChain以及Stable Diffusion的运行有了初步的了解。

其次是对于最重要呈现的结果，也就是通过一张照片生成动态壁纸的这一功能的实现过程进行了一定的设想。

### FaceChain与Stable Diffusion的运行

FaceChain的运行逻辑在09.16的讨论中有所涉猎，其实际的过程就是将用户上传的照片中的人脸信息转化为LoRA模型，再结合本地做好的LoRA，共同交付给Stable Diffusion模型进行图像绘制，最终的结果会是既保留用户上传的人脸信息，又保留本地模型中提供的衣服背景动作等信息的图片。

其中提到的LoRA，可以理解成SD的插件，这个插件可以操控SD，使其生成具有相应特征的图片。LoRA可以通过SD完成注入，因此可以实现一个LoRA和SD的闭环，利用LoRA作为风格化文件来生成对应风格的内容。

### 如何在现有条件下完成动态壁纸的生成

可能方案一：真人出演

用FaceChain把得到的图片，通过其它（可能存在的）模型进行拆分，对人物的毛发，面部，衣物等图层叠加波动扭曲等效果对被遮挡的背景进行补充，使人物能够动起来。

弊端：这样动起来的人或多或少会有些奇怪，容易引起恐怖谷效应。

可能方案二：视频渲视频

用视频生成视频，SD中精细调参，尽可能减少画面闪烁，得到相应画风的视频。

弊端：不满足我们对单张照片成视频的要求，而且仅通过SD就能手动完成，缺少创新性。

可能方案三：二次元微积分

魔改FaceChain，使其输出的图片动漫化，再完成拆分以及背景的补充，添加效果，使人物能够动起来。

弊端：这段过程中需要经过多次AI处理，稳定性和可用性不能保证，且运算时间可能会过长，若市面上存在可靠稳定的模型，此方案相对来讲最为简单。

可能方案四：直出二次元

魔改FaceChain，使其输出的图片动漫化，且分层输出，跳过引用其它模型对图像进行处理的过程，对每一层分别添加效果，使视频动起来。

弊端：这一方案如果能做到，那将是极好的，但是其中需要对FaceChain进行大量的魔改，学习成本巨大，不能保证在短时间内能完成学习与研发。

### Another thought（另一个想法）

在讨论中提到了LoRA社区，用户可以上传自己做的衣服，背景LoRA，供其他用户使用。

#### 由LoRA社区引发的新想法

在AI相机的基础上制作一个电商平台，卖家可以将自己的衣服LoRA以及淘宝京东链接上传到LoRA社区，买家可以下载LoRA（或者不用下载，在服务端完成），实现虚拟试穿。

##### 电商平台操作方法

**卖家**：

1. 拍摄多角度的衣服照片多张，上传到社区，同时附带淘宝京东等平台链接。
2. 服务端，接受到多张衣服照片，照片经过stablediffusion处理生成服装LoRA。
3. 买家自行实验LoRA是否满意，若满意可以上传社区。

**买家**：

1. 在社区中选择想要试穿的衣服。（先上传多张自己的照片，已经生成了人物的LoRA）
2. 服务端，stablediffusion实现人脸和服饰LoRA的结合。
3. 可以保存图片，如果对试穿结果满意，可以进入淘宝京东等电商链接，进一步查询。

##### 相较于单纯的动态相册的优点

单纯的动态相册仅仅在虚拟层面提供虚拟服务，应用性较差。电商平台实现了虚拟世界服务真实世界，应用性较强。

#### 问题

目前得物有虚拟换装功能。如果可以做出虚拟换装的话，只能实现服饰外观测试，不能实现服饰尺寸测试。
